import logging
from app.domain.chat.flows import Flow
from app.config.openai_config import openai_config
from app.services.narratives.chat_prompter import ChatPrompter  # ë„¤ê°€ ì“°ëŠ” ê²½ë¡œ ìœ ì§€
from app.domain.recommend.presenter import RecommendationPresenter
from app.schemas.chat.basic_chat_request import BasicChatRequest
from app.schemas.chat.basic_chat_response import BasicChatResponse
from app.services.redis_service import RedisService
from app.domain.recommend.recommend_service import RecommendService
from app.services.narratives.chat_payload_builder import ChatPayloadBuilder  # ë„¤ê°€ ë§Œë“  ë¹Œë” ê²½ë¡œ

logger = logging.getLogger(__name__)

class ChatService:
    def __init__(self):
        self.redis_service = RedisService()
        self.recommend_service = RecommendService()

    async def _generate_llm_response(self, system_message: str, user_message: str) -> str: 
        """ OpenAI LLMì„ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„± """ 
        try: 
            client = openai_config.get_client() 
            params = openai_config.get_chat_completion_params( system_message=system_message, user_message=user_message ) 
            response = await client.chat.completions.create(**params) 
            return response.choices[0].message.content
        except Exception as e: # LLM í˜¸ì¶œ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ë©”ì‹œì§€ ë°˜í™˜
            logger.error(f"LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return "ì£„ì†¡í•´ìš”, ì ì‹œ ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

    async def _validate_hobby(self, user_input: str) -> tuple[bool, str]:
        """ì·¨ë¯¸ ì…ë ¥ ê²€ì¦ ë° ì •ì œ"""
        try:
            client = openai_config.get_client()
            system_message = ChatPrompter.get_hobby_validation_prompt()

            params = openai_config.get_chat_completion_params(
                system_message=system_message,
                user_message=user_input
            )
            response = await client.chat.completions.create(**params)
            llm_response = response.choices[0].message.content.strip()

            if llm_response.startswith("VALID:"):
                # "VALID:ë…ì„œ,ìš”ë¦¬" í˜•íƒœì—ì„œ ì·¨ë¯¸ ì¶”ì¶œ
                hobbies = llm_response[6:].strip()  # "VALID:" ì œê±°
                return True, hobbies
            else:
                # INVALIDì¸ ê²½ìš°
                return False, ""

        except Exception as e:
            logger.error(f"ì·¨ë¯¸ ê²€ì¦ LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            # LLM ì‹¤íŒ¨ì‹œ ê¸°ë³¸ì ì¸ í•„í„°ë§ë§Œ ì ìš©
            if len(user_input.strip()) < 2 or any(char in user_input for char in ["ã…‹", "ã…", "!"*3, "?"*3]):
                return False, ""
            return True, user_input.strip() 
            
    async def _generate_updated_summary(self, session_id: str, current_summary: str, user_message: str, assistant_message: str) -> str: 
        """ê¸°ì¡´ ìš”ì•½ë³¸ì„ ìƒˆë¡œìš´ ëŒ€í™” ë‚´ìš©ê³¼ í•©ì³ì„œ ê°±ì‹ """ 
        try: 
            client = openai_config.get_client() 
            # PayloadBuilderë¡œ í˜ì´ë¡œë“œ êµ¬ì„± 
            payload = ChatPayloadBuilder.build_summary_update_payload( session_id, current_summary, user_message, assistant_message ) 
            params = openai_config.get_chat_completion_params( system_message=payload["system_message"], user_message=payload["user_message"] ) 
            response = await client.chat.completions.create(**params) 
            new_summary = response.choices[0].message.content.strip() # ìƒˆë¡œìš´ ìš”ì•½ë³¸ ì €ì¥ (ì„¸ì…˜ ê¸°ë°˜) 
            self.redis_service.save_conversation_summary(session_id, new_summary) 
            return new_summary 
        except Exception as e: 
            logger.error(f"ìš”ì•½ë³¸ ê°±ì‹  ì‹¤íŒ¨: session_id={session_id}, error={e}") 
            # ì‹¤íŒ¨ì‹œ ê¸°ì¡´ ìš”ì•½ë³¸ ë°˜í™˜ 
            return current_summary

    async def generate_chat(self, request: BasicChatRequest) -> BasicChatResponse:
        # 1) ì •ê·œí™”
        request.hobby = ChatPayloadBuilder.normalize_hobby(request.hobby)

        message = ""
        new_hobby = ""
        products: list = []  # ì•ˆì „ ì´ˆê¸°í™”

        # 2) ë¹„ì¶”ì²œ ë‹¨ê³„: LLM í˜¸ì¶œ
        if request.flow in (Flow.MOOD_CHECK.value, Flow.HOBBY_CHECK.value, Flow.CHOOSE.value):
            system_message = ChatPrompter.get_system_prompt_for_flow(
                request.flow, request.customer_info.name, request.hobby
            )
            user_message = ChatPayloadBuilder.build_user_message(request)
            message = await self._generate_llm_response(system_message, user_message)

        # 3) ì¶”ì²œ ë‹¨ê³„: RecommendService + Presenter (LLM ë¶ˆí•„ìš”)
        elif request.flow in (Flow.RECOMMENDATION.value, Flow.RE_RECOMMENDATION.value):
            if request.flow == Flow.RECOMMENDATION.value:
                # ì´ˆê¸° ì¶”ì²œ: ìƒˆë¡œìš´ ìƒí’ˆ ê²€ìƒ‰ í›„ ìºì‹±
                keyword, price_range = await self.recommend_service.generate_keywords_async(
                    hobby=request.hobby,
                    mood=request.mood,
                    credit_limit=request.customer_info.credit_limit,
                    balance=request.balance
                )
                products = await self.recommend_service.search_products_async(keyword=keyword, price_range=price_range)

                # ìƒí’ˆ 5ê°œë¥¼ Redisì— ìºì‹± (session í‚¤ ì „ëµ)
                if products:
                    # ì²« ë²ˆì§¸ ìƒí’ˆë§Œ ë°˜í™˜í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ìºì‹±
                    current_product = products[0] if products else None
                    if len(products) > 1:
                        # ë‚˜ë¨¸ì§€ ìƒí’ˆë“¤ì„ ìºì‹± (ì²« ë²ˆì§¸ ì œì™¸)
                        self.redis_service.save_products(request.session_id, products[1:])

                    products = [current_product] if current_product else []
                else:
                    products = []

            elif request.flow == Flow.RE_RECOMMENDATION.value:
                # ì¬ì¶”ì²œ: Redisì—ì„œ ìºì‹±ëœ ìƒí’ˆ í•˜ë‚˜ì”© êº¼ë‚´ê¸°
                cached_product = self.redis_service.pop_product(request.session_id)

                if cached_product:
                    products = [cached_product]
                else:
                    # ìºì‹±ëœ ìƒí’ˆì´ ì—†ìœ¼ë©´ ì„ì‹œ ë©”ì‹œì§€
                    message = "ì£„ì†¡í•´ìš”, ë” ì´ìƒ ì¶”ì²œí•  ìƒí’ˆì´ ì—†ì–´ìš”. ìƒˆë¡œìš´ ì·¨ë¯¸ë‚˜ ê¸°ë¶„ì„ ì•Œë ¤ì£¼ì‹œë©´ ë‹¤ì‹œ ì¶”ì²œí•´ë“œë¦´ê²Œìš”!"
                    products = []

            # ìƒí’ˆì´ ìˆì„ ë•Œë§Œ í…ìŠ¤íŠ¸ êµ¬ì„±
            if products and request.flow == Flow.RECOMMENDATION.value:
                message = RecommendationPresenter.render_text(
                    hobby=request.hobby or "ì§€ê¸ˆ ì·¨ë¯¸",
                    mood=request.mood or "",
                    products=products
                )
            elif products and request.flow == Flow.RE_RECOMMENDATION.value:
                message = RecommendationPresenter.render_text(
                    hobby=request.hobby or "ì§€ê¸ˆ ì·¨ë¯¸",
                    mood=request.mood or "",
                    products=products
                )
            # messageê°€ ì´ë¯¸ ì„¤ì •ëœ ê²½ìš° (ìƒí’ˆ ì—†ìŒ)ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€

        else:
            # ë°©ì–´: í—ˆìš©ë˜ì§€ ì•Šì€ ë‹¨ê³„ â†’ mood_checkë¡œ ìœ ë„
            system_message = ChatPrompter.get_system_prompt_for_flow(
                Flow.MOOD_CHECK.value, request.customer_info.name, request.hobby
            )
            user_message = ChatPayloadBuilder.build_user_message(request)
            message = await self._generate_llm_response(system_message, user_message)

        # 4) choose ë‹¨ê³„ì—ì„œì˜ ì·¨ë¯¸ ì—…ë°ì´íŠ¸ ì •ì±… + ê²€ì¦
        if request.flow == Flow.CHOOSE.value:
            customer_id = str(request.customer_info.customer_id)
            user_input = request.input_message or ""

            if user_input:
                # ì·¨ë¯¸ ê²€ì¦
                is_valid, validated_hobby = await self._validate_hobby(user_input)

                if is_valid:
                    # ìœ íš¨í•œ ì·¨ë¯¸ì¸ ê²½ìš° ì €ì¥
                    new_hobby = validated_hobby
                    self.redis_service.save_user_hobby(customer_id, new_hobby)
                else:
                    # ìœ íš¨í•˜ì§€ ì•Šì€ ì·¨ë¯¸ì¸ ê²½ìš° ì¬ì…ë ¥ ìš”ì²­
                    message = "ìŒ.. ê·¸ ì…ë ¥ì€ ì·¨ë¯¸ë¡œ ì¸ì‹í•˜ê¸° ì–´ë ¤ì›Œ ğŸ˜… ì‹¤ì œ ì·¨ë¯¸ë‚˜ ê´€ì‹¬ì‚¬ë¥¼ ì•Œë ¤ì¤„ë˜? (ì˜ˆ: ë…ì„œ, ê²Œì„, ìš”ë¦¬, ìš´ë™ ë“±)"
                    new_hobby = ""  # ì·¨ë¯¸ ì—…ë°ì´íŠ¸ ì•ˆí•¨
            else:
                new_hobby = ""

        # 5) ìš”ì•½ ê°±ì‹  (ì¶”ì²œ ë‹¨ê³„ë„ í¬í•¨)
        try:
            await self._generate_updated_summary(
                session_id=request.session_id,
                current_summary=request.summary,
                user_message=request.input_message,
                assistant_message=message
            )
        except Exception as e:
            logger.error(f"ìš”ì•½ë³¸ ê°±ì‹  ì¤‘ ì˜¤ë¥˜: {e}")

        # 6) ì‘ë‹µ
        return BasicChatResponse.of(
            message=message,
            session_id=request.session_id,
            new_hobby=new_hobby,
            products=products
        )